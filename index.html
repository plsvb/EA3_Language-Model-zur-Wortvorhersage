<!DOCTYPE html>
<html lang="de">
<head>
  <meta charset="UTF-8">
  <title>Next‑Word Prediction mit LSTM & TensorFlow.js</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Favicon -->
  <link rel="icon" href="/favicon.svg" type="image/x-icon">

  <!-- Bootstrap CSS -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
  <!-- Icons -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.1/font/bootstrap-icons.css" rel="stylesheet">

  <!-- TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
  <!-- D3.js -->
  <script src="https://d3js.org/d3.v7.min.js"></script>

  <style>
    body {
      background: #f8f9fa;
      min-height: 100vh;
      display: flex;
      flex-direction: column;
    }
    main {
      flex: 1;
      padding-top: 4em; /* Platz für sticky Header */
    }
    header {
      position: sticky;
      top: 0;
      z-index: 1000;
    }
    #chart {
      width: 100%;
      height: 200px;
    }
    footer {
      background: #212529;
      color: #dee2e6;
      padding: 1rem 0;
      text-align: center;
    }
  </style>
</head>
<body>

<!-- STICKY HEADER MIT BURGER-MENU -->
<header class="navbar navbar-expand-lg navbar-dark bg-dark shadow-sm fixed-top">
  <div class="container">
    <!-- Branding / Titel -->
    <a class="navbar-brand fw-semibold" href="#">
      <i class="bi bi-lightning-charge-fill"></i> Next‑Word Prediction
    </a>

    <!-- Burger Button für Mobile -->
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Navigation umschalten">
      <span class="navbar-toggler-icon"></span>
    </button>

    <!-- Menü-Links -->
    <div class="collapse navbar-collapse" id="navbarNav">
      <ul class="navbar-nav ms-auto">
        <li class="nav-item"><a class="nav-link" href="#anleitung">Anleitung</a></li>
        <li class="nav-item"><a class="nav-link" href="#app">Anwendung</a></li>
        <li class="nav-item"><a class="nav-link" href="#doku">Doku</a></li>
        <li class="nav-item"><a class="nav-link" href="#fazit">Fazit</a></li>
      </ul>
    </div>
  </div>
</header>


  <!-- HAUPTINHALT -->
  <main class="container  ">

    <!-- Einleitung -->
   <section class="card shadow-sm p-3 mb-4 text-center mb-4">
  <h2 class="fw-bold">Interaktive Wortvorhersage mit LSTM</h2>
  <p class="lead text-muted">
    Dieses Language Model wurde auf <strong>50 000 deutschen Nachrichtensätzen aus der Leipzig Corpora Collection</strong> trainiert. 
    Es basiert auf einem rekurrenten Long Short‑Term Memory (LSTM) Netzwerk und wurde für TensorFlow.js konvertiert, 
    um das wahrscheinlichste nächste Wort in einem gegebenen Satz vorzuschlagen.
  </p>
</section>


    <!-- ANLEITUNG ZUERST -->
    <section id="anleitung" class="p-5 mb-5">
      <h3>Anleitung zur Nutzung</h3>
      <p>So kannst du das Language Model interaktiv verwenden:</p>
      <ol>
        <li>Warte, bis das Modell vollständig geladen ist (Status verschwindet automatisch).</li>
        <li>Gib einen Starttext mit vollständigen Wörtern ein.</li>
        <li>Klicke <strong>Vorhersage</strong>, um die wahrscheinlichsten nächsten Wörter zu sehen.</li>
        <li>Wähle ein Wort aus der Liste oder klicke <strong>Weiter</strong>, um das Top‑1 Wort automatisch anzuhängen.</li>
        <li>Mit <strong>Auto</strong> generiert das Modell bis zu 10 Wörter automatisch. <strong>Stopp</strong> unterbricht den Vorgang.</li>
        <li><strong>Reset</strong> löscht den Text und setzt die App zurück.</li>
      </ol>
    </section>

    <!-- APP-BEREICH -->
    <section id="app" class="mb-5">
      <!-- STATUS (wird nach Laden ausgeblendet) -->
      <div id="status" class="alert alert-info text-center mb-4">
        <i class="bi bi-cloud-download"></i> Lade LSTM‑Modell…
      </div>

      <!-- TEXT-EINGABE -->
      <div class="card shadow-sm mb-4">
        <div class="card-body">
          <h5 class="card-title fw-semibold">Starte mit einem Satz</h5>
<p class="text-muted">
  Das Modell nutzt die letzten <strong><span id="seqLenVal">…</span></strong> Wörter als Kontext, um das nächste Wort vorherzusagen.
</p>
          <textarea 
            class="form-control" 
            id="inputText" 
            rows="3" 
            placeholder="Gib hier einen Starttext ein, z. B.: ‚Heute gehe ich‘ …"></textarea>
            
        </div>
         <!-- BUTTONS -->
      <div class="d-flex flex-wrap justify-content-center gap-2 mb-4">
        <button id="predictBtn" class="btn btn-primary" disabled>
          <i class="bi bi-lightning-fill"></i> Vorhersage
        </button>
        <button id="continueBtn" class="btn btn-secondary" disabled>
          <i class="bi bi-arrow-return-right"></i> Weiter
        </button>
        <button id="autoBtn" class="btn btn-success" disabled>
          <i class="bi bi-play-circle"></i> Auto (10 Wörter)
        </button>
        <button id="stopBtn" class="btn btn-warning" disabled>
          <i class="bi bi-stop-circle"></i> Stopp
        </button>
        <button id="resetBtn" class="btn btn-danger" disabled>
          <i class="bi bi-trash"></i> Reset
        </button>
      </div>

      </div>

     
      <!-- TOP-5 VORHERSAGEN -->
      <div class="card shadow-sm mb-4">
        <div class="card-body">
          <h5 class="card-title">Wahrscheinlichste nächste Wörter (Top‑5)</h5>
          <svg id="chart"></svg>
        </div>
      </div>
    </section>

    <!-- DOKUMENTATION -->
<section id="doku" class="card shadow-sm p-5 mb-5">
  <h3>Dokumentation</h3>
  <p>
    Für diese Anwendung wurde ein <strong>Language Model (LM)</strong> zur <em>Next‑Word Prediction</em> entwickelt. 
    Es besteht aus einer <strong>Embedding-Schicht</strong> mit 128 Dimensionen, 
    gefolgt von zwei <strong>LSTM-Schichten</strong> mit jeweils 256 Units und einem finalen <strong>Dense-Layer</strong> 
    mit Softmax-Aktivierung über 10 001 Wörter (inkl. <code>&lt;OOV&gt;</code>). 
    Trainiert wurde mit dem <em>Adam-Optimizer</em> (lr = 0.001) und <em>Categorical Cross‑Entropy</em> als Loss.
  </p>
  <p>
    Als Trainingsdaten wurden <strong>50 000 Sätze</strong> aus der Leipzig Corpora Collection genutzt. 
    Ursprünglich war ein deutlich größerer Datensatz geplant, jedoch konnte die <strong>lokale Maschine die Verarbeitung nicht mehr bewältigen</strong> – 
    der Arbeitsspeicher war ausgelastet und die Hardware lief bei längeren Trainingsphasen <em>sprichwörtlich heiß</em>. 
    Um Abstürze zu vermeiden, wurde die Datenmenge daher begrenzt.
  </p>
  <p>
    Aus denselben Gründen wurden nur <strong>20 Trainings-Epochen</strong> durchgeführt. 
    Mehr Epochen hätten die bereits hohen Systemlasten weiter erhöht und die Gefahr von Überhitzung verstärkt. 
    Zudem sollte bei der relativ kleinen Datenmenge Overfitting vermieden werden.
  </p>
  <p>
    Nach dem Training in Python/Keras wurde das Modell in das <strong>TensorFlow.js-Format</strong> exportiert, 
    sodass die Inferenz direkt im Browser ohne Server stattfinden kann. 
    Für das Frontend werden <strong>Bootstrap</strong> (UI/UX), <strong>D3.js</strong> (Visualisierung der Top‑5‑Wörter) 
    und <strong>TensorFlow.js</strong> (Modellvorhersage) verwendet. 
    Der Tokenizer aus dem Training wurde als <code>tokenizer.json</code> übernommen, um konsistente Wortindizes sicherzustellen.
  </p>
  <p>
    Aufgrund der reduzierten Datenmenge ist das Modell ein <strong>Prototyp</strong> mit begrenztem Wortschatz. 
    Mit einem größeren Korpus und stabileren Trainingsressourcen könnte die Qualität der Vorhersagen und die Abdeckung unbekannter Wörter deutlich verbessert werden.
  </p>
</section>


    <!-- FAZIT / DISKUSSION -->
   <section id="fazit" class="card shadow-sm p-5 mb-5">
  <h3>Fazit & Diskussion</h3>
  <p>
    Bei den Experimenten zeigte sich, dass das Modell zwar prinzipiell Vorhersagen generiert, die Qualität aber eingeschränkt ist. 
    Häufig wurden vor allem sehr allgemeine Funktionswörter wie <em>„einem“, „seiner“, „in“</em> vorhergesagt, was darauf hinweist, 
    dass das Modell eher die Grundstruktur der Sprache gelernt hat, aber weniger semantischen Zusammenhang herstellen kann.
  </p>
  <p>
    Ein weiteres Problem ist die eingeschränkte Datengrundlage: 
    Es konnten nur <strong>50 000 Sätze</strong> verarbeitet werden, da die <strong>lokale Maschine an ihre Grenzen stieß</strong>. 
    Das Training führte zu einer starken Auslastung von RAM und CPU, wodurch längere Trainingsläufe und größere Korpora 
    nicht möglich waren. Um Abstürze und Überhitzung zu vermeiden, wurden die Epochen auf <strong>20</strong> begrenzt. 
  </p>
  <p>
    Dadurch ist der Wortschatz des Modells zwar auf <strong>10 000 Wörter</strong> limitiert, 
    deckt aber viele seltene Begriffe nicht ab. Unbekannte Wörter erscheinen als <code>&lt;OOV&gt;</code>, 
    was die Lesbarkeit der automatisch generierten Texte einschränkt.
  </p>
  <p>
    Zusätzlich zeigt sich bei längeren Generierungen ein <em>Drift</em> in unzusammenhängende oder unlogische Satzfragmente. 
    Dies ist typisch für kleine LSTM-Modelle mit begrenzten Daten, da sie nur lokale Muster statt langfristiger semantischer Kohärenz lernen. 
    Für stabilere Ergebnisse wären <strong>größere Trainingsdaten</strong>, <strong>mehr Epochen</strong> und 
    möglicherweise <strong>leistungsfähigere Modelle (z.&nbsp;B. Transformer)</strong> erforderlich.
  </p>
  <p>
    Insgesamt liefert das Modell aber einen funktionsfähigen Prototypen für die Wortvorhersage, der 
    die Grundidee und Architektur demonstriert, jedoch noch nicht für produktive Anwendungen geeignet ist.
  </p>
</section>

  </main>

  <!-- FOOTER -->
 <footer>
  <div class="container text-center">
    <small>
       2025 Next‑Word Prediction Demo &middot; Erstellt mit TensorFlow.js, Bootstrap & D3.js <br>
      <a href="mailto:lavo1472@bht-berlin.de" class="text-decoration-none text-light">
        <i class="bi bi-envelope-fill"></i> Kontakt
      </a>
    </small>
  </div>
</footer>


  <!-- Bootstrap JS -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"></script>

  <!-- Prediction-Logik -->
  <script src="predict.js"></script>
  <!-- UI -->
  <script src="ui.js"></script>

  <!-- Nach Modell-Laden den Status ausblenden -->
  <script>
    // Diese Funktion wird nach Modell-Laden aufgerufen
    function hideStatusWhenLoaded() {
      const statusDiv = document.getElementById('status');
      if (statusDiv) {
        statusDiv.style.display = 'none';
      }
    }

    // Hook ins Laden des Modells (wenn predict.js fertig ist)
    document.addEventListener("modelLoaded", () => {
      hideStatusWhenLoaded();
    });
  </script>
</body>
</html>
